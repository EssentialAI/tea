### Structure of this book

Reinforcement Learning is not that new. The promise of RL is almost intoxicating. The notion that an RL agent can learn to understand how the world works is mind bending. This also enables a way to understand how our mind works.

#### [1.0] Introduction

This book starts with the very basics of Reinforcement Learning. This sections provides a definition of Reinforcement Learning (RL), important attributes of RL, The characteristics of RL that make it different from Machine Learning, and the most importantly, "The need for RL."

#### [2.0] Mathematical Background
This chapter serves as a review for the required mathematical background for the rest of the book. Chapters in this section include Infinite Series, Approximation, Linear Algebra, and Basic Combinatorics. This section aims to provide intuitive explanation about each of the above listed chapters with required python code for reference.

#### [3.0] Probability Review

This chapter reviews the most important concepts of Probability. This book requires undergraduate level probability as pre-requisite. While it is impossible to cover all the topics in probability, several important ones are discussed in this chapter.

#### [4.0] Multi-Arm Bandit Problem

We then continue to a special case of the reinforcement learning problem called multi-arm bandits. The agent must decide which choice generates the best outcome or reward on average. This simpler instance of the full RL problem is perhaps the best setting to understand and solve challenges fundamental to RL. This module provides an introduction to estimating values, incremental learning, exploration, non-stationarity, and parameter tuning. We continue to develop and combine these ideas in different ways over the next chapters.
