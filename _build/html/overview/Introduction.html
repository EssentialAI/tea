
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>[1.0] Introduction &#8212; The Essential AI</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/custom.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://essentialai.github.io/tea/overview/Introduction.html" />
    <link rel="shortcut icon" href="../_static/brain1.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/lightmode.svg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">The Essential AI</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../lectures/lecture0.html">
   Linear Algebra Review
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../lectures/Lecture-1.html">
   Lecture 1: Introduction to Machine Learning
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/overview/Introduction.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/EssentialAI/tea"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/EssentialAI/tea/issues/new?title=Issue%20on%20page%20%2Foverview/Introduction.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-reinforcement-learning">
   [1.1] What is Reinforcement Learning?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#why-reinforcement-learning">
   [1.2] Why Reinforcement Learning?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#machine-learning">
   [1.3] Machine Learning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#is-reinforcement-learning-same-as-machine-learning">
   [1.4] Is Reinforcement Learning same as Machine Learning?
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>[1.0] Introduction</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-reinforcement-learning">
   [1.1] What is Reinforcement Learning?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#why-reinforcement-learning">
   [1.2] Why Reinforcement Learning?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#machine-learning">
   [1.3] Machine Learning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#is-reinforcement-learning-same-as-machine-learning">
   [1.4] Is Reinforcement Learning same as Machine Learning?
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <!-- #region -->
<p><span class = 'nital'>You can navigate through this page quickly by using the navigation list on the right-hand side of this page.</span></p>
<div class="section" id="introduction">
<h1>[1.0] Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h1>
<p>Let’s say you want to build a robot to pickup empty cans in a room. If you follow a rule-based approach, then the robot might follow the following steps:</p>
<ol class="simple">
<li><p>Localize itself with the room by building a map of the entire room.</p></li>
<li><p>Run a local object detection algorithm to identify empty cans inside the room.</p></li>
<li><p>Then a cloud connection…</p></li>
</ol>
<p>You see that such a simple solution becomes complex very easily.
There is another method to solve this problem. Reinforcement Learning.</p>
<p>Using Reinforcement Learning, the agent (robot) can learn to collect as many cans as possible through trail and error from scratch. <span class = 'hital'>For the agent to learn progressively, we can use “the number of empty cans collected” as the reward.</span> This approach (Reinforcement Learning) would enable the agent to dynamically adapt to changes in the room such as moving furniture around, changing the color of the cans etc., because the agent can simply learn to maximize the reward through trail and error.</p>
<div class="idea admonition">
<p class="admonition-title">Note</p>
<p>Hold on a second! Before we continue any further, one  must understand what an Agent, Environment, Reward are. The above example explains the robust, adaptive nature of RL. This course teaches Reinforcement Learning from basics. Let’s get started.</p>
</div>
<div class="section" id="what-is-reinforcement-learning">
<h2>[1.1] What is Reinforcement Learning?<a class="headerlink" href="#what-is-reinforcement-learning" title="Permalink to this headline">¶</a></h2>
<p><span class = 'hital'>Reinforcement Learning is a field that deals with building models that mimic human behaviour to learn.</span> To completely understand how Reinforcement Learning (RL) models work, let’s try and understand how humans learn.</p>
<p>Humans learn in a “cause and effect” fashion. For example, we humans do not know how to code right from birth. Learning to code is an interactive process. We make errors in the code, debug them, progressively gain experience about the consequences of actions and what actions to perform to achieve maximum success. <span class = 'nital'>Learning from the interaction is a foundational idea underlying nearly all theories of learning and intelligence.</span></p>
<div class="tip admonition">
<p class="admonition-title">What is Reinforcement Learning?</p>
<p>Reinforcement Learning is a field that aims to build models that try to achieve ‘goal-directed learning from interaction.’ <span class = 'hital'>Reinforcement learning (RL) tells you how to make the best decisions, sequentially, within a context, to maximize a real-life measure of success.</span></p>
<p>Learning by ‘reinforcement’ combines two tasks. The first is exploring new situations. The second is using that experience to make better decisions.</p>
</div>
<div class="idea admonition">
<p class="admonition-title">Note</p>
<p>The characteristics of ‘Trial-and-Error based search’ and ‘Delayed Reward’ are the two most important distinguishing features of Reinforcement Learning.</p>
</div>
<p><span class = 'nital'>Differences between Machine Learning and Reinforcement Learning are discussed in detail below.</span></p>
</div>
<div class="section" id="why-reinforcement-learning">
<h2>[1.2] Why Reinforcement Learning?<a class="headerlink" href="#why-reinforcement-learning" title="Permalink to this headline">¶</a></h2>
<p>One key feature of reinforcement learning is that it explicitly considers the <em>whole</em> problem of a goal-directed agent interacting with an uncertain environment. This is in contrast to many approaches that consider subproblems without addressing how they might fit into a larger picture.</p>
<p>Reinforcement learning is part of a decades-long trend within artificial intelligence and machine learning toward greater integration with statistics, optimization, and other mathematical subjects.</p>
<p>For example, the ability of some reinforcement learning methods to learn with parameterized approximators addresses the classical “curse of dimensionality” in operations research and control theory. More distinctively, reinforcement learning has also interacted strongly with psychology and neuroscience, with substantial benefits going both ways. Of all the forms of machine learning, reinforcement learning is the closest to the kind of learning that humans and other animals do, and many of the core algorithms of reinforcement learning were originally inspired by biological learning systems.</p>
</div>
<div class="section" id="machine-learning">
<h2>[1.3] Machine Learning<a class="headerlink" href="#machine-learning" title="Permalink to this headline">¶</a></h2>
<div class="idea admonition">
<p class="admonition-title">Note</p>
<p><a class="reference external" href="https://rl-book.com/">Source</a> I consider ML a child of data science, which is an overarching scientific field that investigates the data generated by phenomena. I dislike the term artificial intelligence (AI) for a similar reason; it is hard enough to
define what intelligence is, let alone specify how it is achieved.</p>
</div>
<p><span class = 'hital'>Supervised Machine Learning.</span>
In this type of Machine Learning, models learn to generalize from numerous training images provided with labels. In Supervised Machine Learning, the data is split into training and test datasets. Each example is a description of a situation together with a specification, the label, of the correct action the system should take to that situation, which is often to identify a category to which the situation belongs.</p>
<p>The objective of this kind of learning is for the system to extrapolate or generalize its responses so that it acts correctly in situations not present in the training set.</p>
<p><span class = 'hital'>Unsupervised Machine Learning.</span>
In this type of Machine Learning, models try to figure out patterns in the data without labels. Unsupervised learning is aimed at finding structures hidden in collections of unlabelled data.</p>
</div>
<div class="section" id="is-reinforcement-learning-same-as-machine-learning">
<h2>[1.4] Is Reinforcement Learning same as Machine Learning?<a class="headerlink" href="#is-reinforcement-learning-same-as-machine-learning" title="Permalink to this headline">¶</a></h2>
<p>Although one might be tempted to think of reinforcement learning as a kind of unsupervised learning (because it does not rely on examples of correct behavior), reinforcement learning tries to maximize a reward signal instead of trying to find a hidden structure.</p>
<p>Reinforcement learning takes a different track compared to Machine Learning, starting with a complete, interactive, goal-seeking agent. All reinforcement learning agents have explicit goals, can sense aspects of their environments, and can choose actions to influence their environments.</p>
<p>When reinforcement learning involves planning, it has to address the interplay between planning and real-time action selection, as well as the question of how environment models are acquired and improved.</p>
<!-- #### [0.1.5] Reinforcement Learning Fundamentals
<span style="color:blue;">Agent:</span>
An agent is a software program that learns to make intelligent decisions. For instance, a chess player can be considered an agent since the player learns to make the best moves (decisions) to win the game. Similarly, Mario in a Super Mario Bros video game can be considered an agent since Mario explores the game and learns to make the best moves in the game.

<span style="color:blue;">Environment:</span>
The environment is the world of the agent. The agent interacts within the environments. For example, a chessboard is called the environment for the chess player agent.

<span style="color:blue;">State and Action:</span>
A state is a position or a moment in the environment that the agent can be in. There can be many `positions in the chess board environment` that we discussed earlier. All these positions on the chess board are cosidered to be the state. The movement of the chess player agent (forward, backwward, right, and left) are known as actions. (A state is denoted by $s$, and an action is denoted by $a$).

<span style="color:blue;">Reward:</span>
As we discussed earlier, the agent interacts with the environments by performing actions. Every action has a reward associated to it. This reward is a numerical value, _(+1 or -1 for example)_ that denotes if the agent performed an optimal action or not.

The goal of the RL agent is to `maximize this reward` by performing an optimal set of actions.

<span style="color:blue;">Policy:</span>
A policy defines the learning agent’s way of behaving at a given time.

<span style="color:blue;">Value Functions:</span>
Whereas the reward signal indicates what is good in an immediate sense, a value function specifies what is good in the long run. Roughly speaking, the value of a state is the total amount of reward an agent can expect to accumulate over the future, starting from that state. Rewards are in a sense primary, whereas values, as predictions of rewards, are secondary. Without rewards there could be no values, and the only purpose of estimating values is to achieve more reward. Rewards are basically given directly by the environment, but values must be estimated and re-estimated from the sequences of observations an agent makes over its entire lifetime.

<span style="color:blue;">Model-based and Model-free methods:</span>
Methods for solving reinforcement learning problems that use models and planning are called model-based methods, as opposed to simpler model-free methods that are explicitly trial-and-error learners—viewed as almost the opposite of planning. -->
<!-- #endregion -->
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./overview"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Naresh Kumar<br/>
    
        &copy; Copyright 2022.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>